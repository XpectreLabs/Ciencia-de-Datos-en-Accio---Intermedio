# M√≥dulo 1: Introducci√≥n y Fundamentos de Ciencia de Datos

## :dart: **Objetivo del M√≥dulo**
Al finalizar este m√≥dulo, los participantes comprender√°n qu√© es la Ciencia de Datos, sus aplicaciones, el flujo de trabajo t√≠pico, las herramientas principales y los conceptos b√°sicos de estad√≠stica y probabilidad necesarios para analizar datos. Adem√°s, habr√°n realizado ejercicios pr√°cticos que les permitir√°n afianzar los conocimientos.

---

## **Tema 1: Introducci√≥n y Fundamentos de Ciencia de Datos**

#### **Tema 1.1: ¬øQu√© es la Ciencia de Datos?**

1. **Definici√≥n:**
   - La ciencia de datos es el estudio de datos con el fin de extraer informaci√≥n significativa para empresas. Es un enfoque multidisciplinario que combina principios y pr√°cticas del campo de las matem√°ticas, la estad√≠stica, la inteligencia artificial y la ingenier√≠a de computaci√≥n para analizar grandes cantidades de datos. Este an√°lisis permite que los cient√≠ficos de datos planteen y respondan a preguntas como ‚Äúqu√© pas√≥‚Äù, ‚Äúpor qu√© pas√≥‚Äù, ‚Äúqu√© pasar√°‚Äù y ‚Äúqu√© se puede hacer con los resultados‚Äù.
     
   -  <img src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_512,h_288/https://datademia.es/wp-content/uploads/2022/09/Captura-de-Pantalla-2022-09-15-a-las-7.51.49-1024x575.png" alt="Descripci√≥n de la imagen" width="700">
      
   
2. **Aplicaciones pr√°cticas:**
   - **Predicci√≥n de ventas**
      - **Descripci√≥n:** Permite estimar las ventas futuras bas√°ndose en datos hist√≥ricos y patrones observados. Esto ayuda a las empresas a planificar estrategia
        de inventario, producci√≥n y marketing.
      - **Ejemplo:** Una cadena de supermercados utiliza datos de ventas pasadas, estacionalidad y factores externos como el clima para prever la demanda
        de ciertos productos durante las festividades.
      - **Herramientas utilizadas:** Modelos de series temporales como ARIMA, Prophet, o t√©cnicas de Machine Learning como regresi√≥n lineal y √°rboles de decisi√≥n.
   - **An√°lisis de comportamiento del cliente**
      - **Descripci√≥n:** Identifica patrones en el comportamiento del cliente, como preferencias de compra, h√°bitos de consumo y propensi√≥n a abandonar un
        servicio (churn). Esto permite personalizar ofertas, mejorar la experiencia del cliente y aumentar la retenci√≥n.
      - **Ejemplo pr√°ctico:** Una plataforma de streaming analiza las preferencias de visualizaci√≥n de sus usuarios para recomendar contenido relevante y dise√±ar         campa√±as de marketing dirigidas.
      - **Herramientas utilizadas:** Clustering (por ejemplo, K-means), an√°lisis de cohortes y modelos de recomendaci√≥n.
   - **Modelado de riesgo en finanzas**
      - **Descripci√≥n:** Eval√∫a la probabilidad de eventos negativos, como incumplimiento de pagos o fluctuaciones en el mercado, para mitigar riesgos y tomar
        decisiones informadas.
      - **Ejemplo pr√°ctico:** Un banco utiliza modelos predictivos para evaluar la probabilidad de que un cliente incumpla el pago de un pr√©stamo, bas√°ndose en
        datos como ingresos, historial crediticio y nivel de endeudamiento.
      - **Herramientas utilizadas:** Modelos de clasificaci√≥n como Random Forest, Logistic Regression, y t√©cnicas de an√°lisis de series temporales.
   - **Detecci√≥n de fraudes**
      - **Descripci√≥n:** Identifica actividades sospechosas o fraudulentas al analizar transacciones y comportamientos en tiempo real. Esto es fundamental para
        prevenir p√©rdidas financieras y proteger la seguridad de los usuarios.
      - **Ejemplo pr√°ctico:** Un sistema de pagos electr√≥nicos monitorea transacciones inusuales, como compras de alto valor desde ubicaciones geogr√°ficas
        inusuales, y las marca para su revisi√≥n.
      - **Herramientas utilizadas:** Algoritmos de detecci√≥n de anomal√≠as, redes neuronales, y t√©cnicas de aprendizaje supervisado o no supervisado.
        
   - <img src="https://www.caosyciencia.com/wp-content/uploads/2024/10/ejemplos-de-dashboard-excel-para-mejorar-tu-toma-de-decisiones.jpg" alt="Descripci√≥n de la imagen" width="700">
   
4. **Rol de un Cient√≠fico de Datos:** El cient√≠fico de datos es un profesional interdisciplinario que combina habilidades t√©cnicas, anal√≠ticas y de comunicaci√≥n para transformar datos en informaci√≥n valiosa para la toma de decisiones. Algunas responsabilidades:
   
      - **Formular preguntas clave:**
         - El punto de partida es entender qu√© problemas necesitan resolverse. Esto implica traducir problemas del mundo real en preguntas que puedan responderse con datos.
         - Ejemplo:
            - "¬øQu√© factores aumentan la satisfacci√≥n del cliente?"
            - "¬øC√≥mo podemos optimizar nuestro inventario seg√∫n patrones de compra?"
         - Un buen cient√≠fico de datos sabe que las preguntas correctas gu√≠an todo el an√°lisis.
           
      - **Manejar grandes vol√∫menes de datos:**
         - Los datos provienen de m√∫ltiples fuentes, como bases de datos, redes sociales o sensores IoT. Este paso incluye:
            - Recolectar datos de manera estructurada (tablas, bases de datos) y no estructurada (im√°genes, texto).
            - Limpiar y preparar los datos eliminando errores, valores at√≠picos o datos incompletos.
            - Integrar diferentes fuentes de datos para obtener una visi√≥n completa.
         - Ejemplo: analizar ventas, datos de marketing y rese√±as de clientes juntos para detectar patrones.
           
      - **Construir modelos predictivos:**
         - Utilizando Machine Learning y estad√≠stica avanzada, un cient√≠fico de datos desarrolla modelos que pueden:
            - Predecir comportamientos (como compras futuras o abandono de clientes).
            - Detectar anomal√≠as, como posibles fraudes o errores.
            - Optimizar procesos, como la asignaci√≥n de recursos o la gesti√≥n de inventarios.
         - Estos modelos permiten a las empresas tomar decisiones basadas en evidencia.
           
      - **Comunicar resultados de manera efectiva:**
         - La habilidad de presentar informaci√≥n t√©cnica a un p√∫blico no t√©cnico es crucial. Esto se logra mediante:
            - Dashboards interactivos que muestran m√©tricas clave en tiempo real.
            - Visualizaciones claras como gr√°ficos y diagramas.
            - Reportes ejecutivos con conclusiones pr√°cticas y recomendaciones.
         - Ejemplo: un dashboard para mostrar las m√©tricas de rendimiento de una campa√±a de marketing en tiempo real.
           
      - **Otros roles clave:**
         - Experimentar con nuevas tecnolog√≠as: Adoptar herramientas como Python, R, TensorFlow o AWS.
         - Colaborar con diferentes √°reas: Trabajar con marketing, finanzas, operaciones y tecnolog√≠a para resolver problemas desde diferentes perspectivas.
         - Mantener la curiosidad: Buscar oportunidades en los datos y estar dispuesto a aprender constantemente sobre nuevos enfoques y tendencias.


**Ejemplo pr√°ctico:**
- Caso simplificado: Analizar datos de ventas mensuales para identificar tendencias y realizar predicciones.
- [Ejemplo](modulo-01/Ejemplo_practico1.ipynb)

**Ejercicio para los alumnos:**
- Identificar tres problemas en su √°rea laboral o personal donde podr√≠a aplicarse Ciencia de Datos.

---

#### **Tema 1.2: Flujo de Trabajo en Ciencia de Datos**

1. **Etapas principales:**
   - **Obtenci√≥n de datos**
      - Este es el primer paso en el flujo de trabajo, donde se recolectan los datos necesarios para resolver un
        problema o responder una pregunta. Los datos pueden provenir de diversas fuentes:
         - **APIs:** Interfaces que permiten extraer datos en tiempo real desde aplicaciones o servicios (por ejemplo,
           datos meteorol√≥gicos o redes sociales).
         - **Bases de datos:** Sistemas organizados para almacenar y gestionar grandes cantidades de datos
           estructurados.
         - **Archivos locales:** Archivos como CSV, Excel o JSON que contienen datos sin conexi√≥n.
         - **Web scraping:** Extracci√≥n automatizada de datos de sitios web.
      ```python
      import pandas as pd
      df = pd.read_csv('ventas_mensuales.csv')
      print(df.head())

   - **Limpieza de datos:**
      - Este paso es crucial para asegurar que los datos sean utilizables. Se eliminan errores, valores
        inconsistentes, duplicados y datos faltantes.
         - **Inconsistencias:** Resolver problemas como diferentes formatos de fecha o errores tipogr√°ficos.
         - **Valores nulos:** Manejar celdas vac√≠as mediante imputaci√≥n (reemplazar valores nulos con la media,
           mediana, etc.) o eliminaci√≥n.
         - **Outliers (valores at√≠picos):** Identificar y decidir si estos valores extremos deben eliminarse o
           tratarse.
     ```python
     #Usar Pandas para eliminar valores nulos: 
      df = df.dropna()
     
     #Detectar y tratar valores at√≠picos: 
      Q1 = df['Ventas'].quantile(0.25)
      Q3 = df['Ventas'].quantile(0.75)
      IQR = Q3 - Q1
      outliers = df[(df['Ventas'] < (Q1 - 1.5 * IQR)) | (df['Ventas'] > (Q3 + 1.5 * IQR))]
   - **An√°lisis exploratorio**
      - En esta etapa, los datos se analizan para identificar patrones, tendencias y relaciones clave. Este
        proceso ayuda a formular hip√≥tesis y guiar la construcci√≥n de modelos.
         - Estad√≠sticas descriptivas: Res√∫menes de los datos, como la media, mediana, moda, rango y desviaci√≥n
           est√°ndar.
         - Visualizaciones: Usar gr√°ficos como histogramas, diagramas de dispersi√≥n y boxplots para entender
           los datos.
     ```python
     #Generar gr√°ficos para entender patrones: 
      df['Ventas'].hist()
      plt.title('Distribuci√≥n de Ventas')
      plt.show()
   - **Modelado**
      - En esta etapa se desarrollan modelos predictivos o descriptivos utilizando algoritmos de Machine
        Learning. Esto incluye:
         - Dividir los datos en conjuntos de entrenamiento y prueba.
         - Seleccionar y ajustar un modelo (por ejemplo, regresi√≥n lineal, √°rboles de decisi√≥n o redes
           neuronales).
         - Evaluar el modelo utilizando m√©tricas como precisi√≥n, recall o F1-score.
     ```python
     #Introducci√≥n a un modelo simple de regresi√≥n lineal: 
      from sklearn.linear_model import LinearRegression
      model = LinearRegression()
      X = df[['Mes']]
      y = df['Ventas']
      model.fit(X, y)
      print(f"Coeficiente: {model.coef_}, Intercepto: {model.intercept_}")
   - **Visualizaci√≥n y comunicaci√≥n**
      - Una vez que se obtienen los resultados, es fundamental presentarlos de manera clara y efectiva a las
        partes interesadas. Esto se logra mediante:
         - **Dashboards interactivos:** Usando herramientas como Tableau o Power BI.
         - **Gr√°ficos claros:** Creaci√≥n de gr√°ficos de barras, l√≠neas o mapas de calor.
         - **Reportes:** Documentos estructurados con conclusiones y recomendaciones basadas en el an√°lisis.
      ```python
      #Crear un gr√°fico de barras que muestre las ventas por regi√≥n.
      import seaborn as sns
      sns.barplot(x="Regi√≥n", y="Ventas", data=df)
      plt.title("Ventas por Regi√≥n")
      plt.show()

   
2. **Diagrama del flujo de trabajo:**
   - <img src="https://scontent.fvsa1-2.fna.fbcdn.net/v/t1.6435-9/120273370_652092392159862_5896927628537707756_n.jpg?_nc_cat=100&ccb=1-7&_nc_sid=833d8c&_nc_ohc=UXMv4tXQKdMQ7kNvgHCXBgR&_nc_zt=23&_nc_ht=scontent.fvsa1-2.fna&_nc_gid=ATQVYFnQ6UpatqyFxN7DUuY&oh=00_AYCeJmPjHW4-Q2DmWIZcO5srSn3oXlCKaOhtpjl9kiWmfQ&oe=67B22EF1" alt="Descripci√≥n de la imagen" width="700">
  
4. **Herramientas utilizadas en cada etapa:**
   - **Pandas para manipulaci√≥n de datos**
      - Pandas es una de las librer√≠as m√°s utilizadas en Python para manipular y analizar datos. Permite
        realizar operaciones sobre estructuras como Series y DataFrames, ideales para la limpieza,
        transformaci√≥n y exploraci√≥n de datos.
      - Funciones clave:
         - read_csv(): Leer archivos CSV.
         - dropna(): Eliminar valores nulos.
         - groupby(): Agrupar datos seg√∫n una o m√°s columnas.
         - describe(): Obtener estad√≠sticas descriptivas del conjunto de datos.
           ```python
           import pandas as pd

            # Cargar datos desde un archivo CSV
            df = pd.read_csv("ventas_mensuales.csv")
            
            # Ver las primeras filas del DataFrame
            print(df.head())
            
            # Eliminar registros con valores nulos
            df_clean = df.dropna()
            
            # Agrupar por regi√≥n y calcular la suma de ventas
            ventas_por_region = df_clean.groupby('Regi√≥n')['Ventas'].sum()
            print(ventas_por_region)

   - **Matplotlib para visualizaci√≥n**
      - Matplotlib es una librer√≠a de visualizaci√≥n en Python utilizada para crear gr√°ficos est√°ticos,
        din√°micos e interactivos. Es ampliamente empleada para generar visualizaciones como gr√°ficos de
        barras, l√≠neas, dispersi√≥n, histogramas y m√°s.
      - Funciones clave:
         - plt.plot(): Crear gr√°ficos de l√≠neas.
         - plt.bar(): Crear gr√°ficos de barras.
         - plt.scatter(): Crear gr√°ficos de dispersi√≥n.
         - plt.title(), plt.xlabel(), plt.ylabel(): Etiquetar los gr√°ficos.
           ```python
           import matplotlib.pyplot as plt

            # Crear un gr√°fico de barras para las ventas por regi√≥n
            plt.bar(['Norte', 'Sur', 'Este', 'Oeste'], [1000, 1200, 1300, 1100])
            plt.title("Ventas por Regi√≥n")
            plt.xlabel("Regi√≥n")
            plt.ylabel("Ventas")
            plt.show()

   - **Scikit-learn para modelado**
      - Scikit-learn es una de las librer√≠as m√°s conocidas en Python para aprender modelos de Machine
        Learning. Proporciona herramientas para realizar tareas como regresi√≥n, clasificaci√≥n, agrupamiento,
        reducci√≥n de dimensionalidad y selecci√≥n de modelos.
      - Funciones clave:
         - train_test_split(): Dividir los datos en conjuntos de entrenamiento y prueba.
         - LinearRegression(): Crear modelos de regresi√≥n lineal.
         - fit(): Ajustar el modelo a los datos de entrenamiento.
         - score(): Evaluar el desempe√±o del modelo en los datos de prueba.
           ```python
            from sklearn.model_selection import train_test_split
            from sklearn.linear_model import LinearRegression
            
            # Crear un conjunto de datos para modelado
            X = [[100], [150], [200], [250], [300]]
            y = [150, 200, 250, 300, 350]
            
            # Dividir los datos en entrenamiento y prueba
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            # Crear y ajustar el modelo
            model = LinearRegression()
            model.fit(X_train, y_train)
            
            # Evaluar el modelo
            print("Coeficiente:", model.coef_)
            print("Intercepto:", model.intercept_)
            print("Precisi√≥n del modelo:", model.score(X_test, y_test))


**Ejercicio pr√°ctico:**
- Crear un esquema en Google Colab con encabezados para cada etapa del flujo de trabajo.

---

#### **Tema 1.3: Herramientas Principales de Ciencia de Datos**

1. **Google Colab:**
   - Google Colab es una plataforma basada en la nube que permite ejecutar notebooks de Python directamente
     desde el navegador, eliminando la necesidad de configuraciones locales.
   - Caracter√≠sticas principales:
      - Ejecuci√≥n en la nube: Realiza c√°lculos complejos utilizando recursos en l√≠nea, sin afectar el
      - rendimiento local.
      - Acceso a hardware avanzado: GPUs y TPUs disponibles gratuitamente para tareas como Machine Learning y
      - Deep Learning.
      - Colaboraci√≥n en tiempo real: Similar a Google Docs, permite que varios usuarios editen y ejecuten
        c√≥digo en simult√°neo.
      - Almacenamiento en la nube: Compatible con Google Drive para guardar, acceder y compartir notebooks.
      - Entorno preconfigurado: Incluye bibliotecas populares como NumPy, Pandas, Matplotlib, TensorFlow, y
      - Scikit-learn.
   - Ventajas:
      - Gratuito y accesible desde cualquier lugar con conexi√≥n a internet.
      - Configuraci√≥n cero: ideal para estudiantes y principiantes en ciencia de datos y Machine Learning.
      - Integraci√≥n con herramientas externas: admite datos de APIs, almacenamiento en la nube, y bases de
        datos.
   - Limitaciones:
      - Requiere conexi√≥n a internet para funcionar.
      - Sesiones limitadas en la versi√≥n gratuita (hasta 12 horas).
      - Recursos computacionales compartidos, lo que puede reducir el rendimiento en tareas muy intensivas.
     <img src="https://github.com/user-attachments/assets/53f5ee0e-c69e-4c78-9bab-a0c48089eeb7" alt="Descripci√≥n de la imagen" width="700">
     


     -**Paso a paso**: 
      1.	Abre Google Colab en https://colab.research.google.com.
      2.	Crea un nuevo notebook y dale un t√≠tulo.
      3.	Escribe y ejecuta el siguiente c√≥digo:
         
   ```python
        	print("Hola, Ciencia de Datos!")


2. **Python y sus librer√≠as:**
   - **Pandas**
      - Dise√±ada para trabajar con datos tabulares, como hojas de c√°lculo o bases de datos.
      - Ofrece estructuras como DataFrames y Series, que permiten manipular filas y columnas f√°cilmente.
      - **Funcionalidades clave:**
         - Limpieza de datos: Manejo de valores nulos y duplicados.
         - Filtrado y selecci√≥n: Extracci√≥n de datos espec√≠ficos con condiciones.
         - Transformaci√≥n: Realizaci√≥n de operaciones matem√°ticas o de texto en columnas.
         - Agrupaci√≥n: Resumen de datos por categor√≠as con m√©todos como groupby.
            ```python
            import pandas as pd

            data = {'Mes': [1, 2, 3], 'Ventas': [1000, 1200, 1300]}
            df = pd.DataFrame(data)
            print(df.describe())  # Estad√≠sticas b√°sicas

   - NumPy
      - Proporciona soporte para arreglos multidimensionales y operaciones matem√°ticas r√°pidas.
      - Ideal para c√°lculos num√©ricos de gran escala y operaciones vectorizadas.
      - **Funcionalidades clave:**
         - Creaci√≥n de arrays y matrices.
         - Operaciones matem√°ticas como sumas, productos, y estad√≠sticas.
         - Integraci√≥n con otras bibliotecas como Pandas y Scikit-learn.
           ```python
           import numpy as np

            array = np.array([1, 2, 3, 4])
            print("Media:", np.mean(array))  # Media del array

   - Matplotlib
      - Herramienta para crear gr√°ficos est√°ticos, animados e interactivos.
      - Compatible con otros frameworks como Pandas para graficar datos f√°cilmente.
      - **Tipos de gr√°ficos comunes:**
         - L√≠neas: Ideal para observar tendencias.
         - Barras: Comparaci√≥n entre categor√≠as.
         - Histogramas: Distribuci√≥n de datos.
         - Dispersi√≥n: Relaciones entre dos variables.
            ```python
           import matplotlib.pyplot as plt

            x = [1, 2, 3, 4]
            y = [10, 20, 30, 40]
            
            plt.plot(x, y, marker='o')
            plt.title("Gr√°fico de ejemplo")
            plt.xlabel("Mes")
            plt.ylabel("Ventas")
            plt.show()

   
3. **Dataset de ejemplo:**
   - Usa un dataset de ventas en formato CSV:
   - Dataset: Ventas por Mes y Regi√≥n

      | Mes | Ventas | Regi√≥n |
      |-----|--------|--------|
      | 1   | 1000   | Norte  |
      | 2   | 1200   | Sur    |
      | 3   | 1300   | Este   |

**Ejercicio pr√°ctico:**
1. Carga el dataset anterior en Google Colab:
    ```python
   df = pd.read_csv('ventas_mensuales.csv')
   print(df.head())
2. Explora el dataset con las funciones info() y describe().
3.	Crea un gr√°fico de barras con Matplotlib que muestre las ventas por regi√≥n.

## **Tema 2: Fundamentos de Estad√≠stica y Probabilidad Aplicada**

---
#### **Tema 2.1: Conceptos B√°sicos de Estad√≠stica**

1. **Medidas de tendencia central:**
   - Media
      - La media es el valor promedio de un conjunto de datos. Se calcula sumando todos los valores
        dividiendo entre el n√∫mero total de observaciones.
      - Uso: Es ideal para datos distribuidos de manera uniforme.
      - <img src="https://yosoytuprofe.20minutos.es/wp-content/uploads/2019/04/media-aritm%C3%A9tica-1.jpg" width="700">
     
     ```python
       print("Media:", df['Ventas'].mean())
     
   - Mediana:
      - La mediana es el valor central de un conjunto de datos ordenado.
      - Uso: Es m√°s robusta frente a valores at√≠picos o extremos.
      - C√≥mo calcularla:
         - Si el n√∫mero de observaciones es impar, la mediana es el valor central.
         - Si es par, es el promedio de los dos valores centrales.
     
     ```python
       print("Mediana:", df['Ventas'].median())
     
   - Moda:
      - La moda es el valor que m√°s se repite en un conjunto de datos.
      - Uso: √ötil para datos categ√≥ricos o cuando se desea identificar la frecuencia m√°s alta.
      - Ejemplo:
         - Si las ventas diarias son: [1200, 1500, 1200, 1700], la moda es 1200 porque aparece con mayor
           frecuencia.
        
     ```python
       print("Moda:", df['Ventas'].mode()[0])
   - <img src="https://github.com/user-attachments/assets/57efa55b-ab80-40a3-830d-b97a9e78f17d" width="700">
   
2. **Medidas de dispersi√≥n:**
   - Rango: La diferencia entre el valor m√°ximo y el valor m√≠nimo en un conjunto de datos.

     ```python
     print("Rango:", df['Ventas'].max() - df['Ventas'].min())
   - Varianza: Una medida de la dispersi√≥n que calcula la media de los cuadrados de las diferencias entre los valores y la media del conjunto.

     ```python
       print("Varianza:", df['Ventas'].var())
   - Desviaci√≥n est√°ndar: La ra√≠z cuadrada de la varianza, que representa la dispersi√≥n promedio de los datos en relaci√≥n a su media.

     ```python
       print("Desviaci√≥n est√°ndar:", df['Ventas'].std())
   - <img src="https://bookdown.org/dietrichson/metodos-cuantitativos/metodos-cuantitativos_files/figure-html/box-plot-with-explanation-1.png" width="700">

üìö**Ejercicio pr√°ctico:**
- Crear una lista de n√∫meros y calcular la media, mediana y desviaci√≥n est√°ndar usando Numpy.

---

#### **Tema 2.2: Introducci√≥n a Probabilidad**

1. **Definici√≥n de probabilidad:**
   - La probabilidad es una medida que indica la frecuencia con la que se espera que ocurra un evento en un n√∫mero infinito de ensayos.
   - Se define como el cociente entre el n√∫mero de casos favorables y el n√∫mero total de casos posibles.
   - Ejemplo: Lanzamiento de un dado:
   - El dado tiene 6 caras numeradas (casos posibles).
   - La probabilidad de que salga un n√∫mero par en un solo lanzamiento es el n√∫mero de casos favorables (3 caras: 2, 4, 6) dividido entre el total de casos posibles (6 caras).
   
2. **Distribuciones comunes:**
   - Uniforme: Cada resultado tiene la misma probabilidad.
   - <img src="https://www.lifeder.com/wp-content/uploads/2020/11/distribucion-uniforme-continua.jpg" width="700">
   - Normal: Distribuci√≥n en forma de campana.
   - <img src="https://alianza.bunam.unam.mx/wp-content/uploads/2024/02/Figura-2.-Tipificacion-de-una-curva-normal-por-su-media-y-desviacion-estandar.png" width="700">
   
üìö**Ejercicio pr√°ctico:**
- Generar datos con una distribuci√≥n uniforme y graficar un histograma.

---

#### **Tema 2.3: Representaci√≥n Gr√°fica de Datos**

1. **Tipos de gr√°ficos:**
   - Histogramas: Para distribuciones de datos.
   - <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Histogram_example.svg/1200px-Histogram_example.svg.png" width="700">
   - Diagramas de barras: Para datos categ√≥ricos.
   - <img src="https://www.jmp.com/es_mx/statistics-knowledge-portal/exploratory-data-analysis/bar-chart/_jcr_content/par/styledcontainer_2069/par/image_1203777138.img.png/1594745267192.png" width="700">
   - Gr√°ficos de dispersi√≥n: Para relaciones entre dos variables.
   - <img src="https://static.wixstatic.com/media/d7b433_8b364cba373247b78b4ea3579026a60e~mv2.png/v1/fill/w_528,h_352,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/d7b433_8b364cba373247b78b4ea3579026a60e~mv2.png" width="700">
   
2. **Ejemplo pr√°ctico:**
   - Gr√°fico de barras con ventas por regi√≥n.
   - Gr√°fico de dispersi√≥n con horas de estudio vs calificaciones.

**Ejercicio para los alumnos:**
- Crear un gr√°fico de barras con sus propios datos usando Matplotlib.
- Crear un gr√°fico de dispersi√≥n que relacione dos variables num√©ricas.

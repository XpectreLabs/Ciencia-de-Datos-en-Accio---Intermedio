{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación de un Modelo de Clasificación\n",
        "\n",
        "Descripción:\n",
        "En este ejercicio, evaluaremos un modelo de clasificación utilizando métricas comunes como la matriz de confusión y el informe de clasificación. Estas métricas nos ayudan a entender el rendimiento del modelo en términos de precisión, recall, F1-score y más.\n",
        "\n",
        "Tareas:\n",
        "1. Definir las etiquetas reales (`y_true`) y las etiquetas predichas (`y_pred`).\n",
        "2. Calcular la matriz de confusión.\n",
        "3. Generar un informe de clasificación que incluya métricas clave."
      ],
      "metadata": {
        "id": "IVjkqlQ7IErs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ITGxZ4EdIDYH"
      },
      "outputs": [],
      "source": [
        "# Paso 1: Importar las librerías necesarias\n",
        "# -------------------------------------------\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Paso 2: Definir las etiquetas reales y las etiquetas predichas\n",
        "# -------------------------------------------\n",
        "# `y_true` contiene las etiquetas reales y `y_pred` contiene las predicciones del modelo.\n",
        "y_true = [0, 1, 0, 1, 0]  # Etiquetas reales\n",
        "y_pred = [0, 1, 0, 0, 1]  # Etiquetas predichas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 3: Calcular la matriz de confusión\n",
        "# -------------------------------------------\n",
        "# La matriz de confusión resume los resultados de las predicciones del modelo.\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matriz de Confusión:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZBRBPBjIMhx",
        "outputId": "fbb0682f-30e2-4338-b4f8-c2bd5854b3d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión:\n",
            "[[2 1]\n",
            " [1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 4: Generar el informe de clasificación\n",
        "# -------------------------------------------\n",
        "# Este informe incluye métricas como precisión, recall, F1-score y soporte para cada clase.\n",
        "class_report = classification_report(y_true, y_pred)\n",
        "print(\"\\nInforme de Clasificación:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMET7w1bIPz5",
        "outputId": "ab0b0ce0-ceeb-45b0-d7cc-fbba3da48050"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Informe de Clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.67      0.67         3\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "    accuracy                           0.60         5\n",
            "   macro avg       0.58      0.58      0.58         5\n",
            "weighted avg       0.60      0.60      0.60         5\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
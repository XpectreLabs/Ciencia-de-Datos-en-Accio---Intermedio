# M칩dulo 4: Fundamentos de Machine Learning 

## 游꿢Objetivo del M칩dulo
Al finalizar este m칩dulo, los participantes comprender치n los conceptos clave de Machine Learning, los diferentes tipos de aprendizaje, y ser치n capaces de construir y evaluar modelos supervisados y no supervisados utilizando **Scikit-learn**.

---

## Tema: Introducci칩n a Machine Learning

### Tema 4.1: Supervisado vs No Supervisado


#### 쯈u칠 es Machine Learning?  
- Machine Learning es un campo de la inform치tica que se enfoca en desarrollar algoritmos y modelos que permiten a las m치quinas aprender patrones y a partir de esos patrones, realizar predicciones o tomar decisiones autom치ticamente. A diferencia de los enfoques tradicionales de programaci칩n, donde los resultados son definidos expl칤citamente, el Machine Learning permite que los sistemas aprendan de los datos y mejoren su rendimiento sin la necesidad de programaci칩n expl칤cita para cada caso.

- **Aplicaciones comunes**:
  1. **Predicci칩n de precios de bienes o servicios**:
     - Los modelos de Machine Learning, como los algoritmos de regresi칩n, se utilizan para predecir el precio de bienes, como casas, acciones burs치tiles o productos. Estos modelos pueden tener en cuenta m칰ltiples variables como la ubicaci칩n, el tama침o, las tasas de inter칠s, el historial econ칩mico, etc.

  2. **Clasificaci칩n de correos electr칩nicos como spam o no spam**:
     - Un ejemplo cl치sico de Machine Learning supervisado es el filtrado de correos electr칩nicos. Los modelos, como los basados en **Machine Learning** supervisado (como la Regresi칩n Log칤stica o M치quinas de Soporte Vectorial), aprenden a distinguir entre correos leg칤timos y mensajes de **spam** mediante el an치lisis de caracter칤sticas del contenido, el remitente y el asunto.

  3. **Agrupamiento de clientes seg칰n sus caracter칤sticas de compra**:
     - Utilizando t칠cnicas como el Clustering, se pueden agrupar clientes en segmentos basados en su comportamiento de compra, intereses, geolocalizaci칩n, patrones de gasto, etc. Esto permite a las empresas personalizar sus estrategias de marketing y ofrecer productos que coincidan con los h치bitos de consumo de cada segmento.
  
  4. **Recomendaci칩n de productos**:
     - A trav칠s del aprendizaje autom치tico, se pueden construir sistemas de recomendaci칩n que sugieren productos a los usuarios basados en su historial de compras anteriores, visualizaciones, calificaciones o preferencias. Por ejemplo, plataformas como Netflix, Amazon y Spotify utilizan estos sistemas para mejorar la experiencia del usuario.

  5. **An치lisis de sentimiento**:
     - El Machine Learning tambi칠n es empleado para analizar el sentimiento en redes sociales, opiniones de usuarios, o textos, identificando si un mensaje tiene un tono positivo, negativo o neutro. Los modelos de clasificaci칩n textuales permiten entender las emociones subyacentes en los datos textuales.

  6. **Reconocimiento de voz y procesamiento de lenguaje natural**:
     - Los sistemas de Machine Learning, como los modelos de **Deep Learning** y redes neuronales recurrentes, se utilizan para convertir el habla en texto (sistemas de reconocimiento de voz) o para analizar y comprender el lenguaje humano en aplicaciones como asistentes virtuales (Siri, Alexa) o traducci칩n autom치tica.

  7. **Diagn칩stico en salud**:
     - Los modelos de Machine Learning tambi칠n se aplican en el sector salud para diagnosticar enfermedades, como la detecci칩n temprana de c치ncer a trav칠s de an치lisis de im치genes m칠dicas (radiograf칤as, resonancias magn칠ticas) o para el an치lisis de datos gen칠ticos.

---


#### Tipos principales de aprendizaje:

### 1. Machine Learning Supervisado:
- Los modelos de Machine Learning supervisado aprenden de datos etiquetados, es decir, cada entrada en el conjunto de datos tiene una salida conocida y predefinida. Este tipo de aprendizaje implica la utilizaci칩n de ejemplos previamente clasificados para entrenar el modelo, permiti칠ndole generalizar patrones y realizar predicciones sobre datos nuevos.

- **Ejemplo pr치ctico**:
  - **Predecir el precio de una casa**: Un modelo de Machine Learning supervisado puede predecir el precio de una casa basado en caracter칤sticas como el tama침o, la ubicaci칩n, la antig칲edad, el n칰mero de habitaciones, los servicios cercanos, entre otros. El modelo se entrena utilizando un conjunto de datos que incluye precios reales de casas junto con sus respectivas caracter칤sticas.

- **Caracter칤sticas**:
  - **Entrenamiento**: El modelo se entrena con datos etiquetados, donde se conocen las respuestas correctas.
  - **Salida**: El modelo proporciona una respuesta espec칤fica y cuantificada, como un precio o una clasificaci칩n (por ejemplo, clasificar un correo como **spam** o **no spam**).
  - **Modelos comunes**:
    - **Regresi칩n lineal**: Se utiliza para hacer predicciones continuas, como el precio de una casa basado en caracter칤sticas num칠ricas.
    - **Regresi칩n log칤stica**: Muy 칰til para problemas de clasificaci칩n binaria, como la clasificaci칩n de correos electr칩nicos.
    - **M치quinas de Soporte Vectorial (SVM)**: Son eficaces cuando los datos est치n separados por m치rgenes definidos.
    - **츼rboles de Decisi칩n**: Permiten la creaci칩n de modelos interpretables que dividen el espacio de entrada en regiones que maximizan la pureza de clasificaci칩n.

---

### 2. Machine Learning No Supervisado:
- Los modelos de Machine Learning no supervisado no aprenden con datos etiquetados, sino que buscan patrones, agrupamientos o relaciones en los datos sin una gu칤a expl칤cita sobre las salidas. Este tipo de aprendizaje permite descubrir estructuras en los datos que son 칰tiles para la interpretaci칩n y segmentaci칩n.

- **Ejemplo pr치ctico**:
  - **Agrupar clientes en segmentos seg칰n su comportamiento de compra**: Un modelo de Machine Learning no supervisado puede utilizar algoritmos como K-Means para identificar clusters de clientes con caracter칤sticas similares en t칠rminos de sus patrones de compra, edad, ingresos, o h치bitos.

- **Caracter칤sticas**:
  - **Entrenamiento**: El modelo es entrenado con datos no etiquetados, donde la informaci칩n no incluye resultados previamente definidos.
  - **Salida**: Los resultados son estructuras como clusters, agrupamientos o caracter칤sticas de similitud que ayudan a entender los datos desde una perspectiva nueva.
  - **Modelos comunes**:
    - **Algoritmos de agrupamiento (Clustering)**:
      - **K-Means**: Divide los datos en `k` clusters de acuerdo con la proximidad.
      - **Clustering jer치rquico**: Construye una jerarqu칤a de clusters mediante divisiones sucesivas.
      - **Aprendizaje Basado en Vecinos Cercanos**: Agrupa los puntos en funci칩n de la proximidad a otros puntos en el espacio de caracter칤sticas.


#### Ciclo de vida de un modelo de Machine Learning:
1. **Recopilaci칩n de datos**: 
   - Obtener datos relevantes y estructurados para el problema que se desea resolver. 
   - Ejemplo: Datos de clientes, hist칩rico de ventas, etc.

2. **Preprocesamiento**:
   - Limpiar y transformar los datos para que puedan ser utilizados en el modelo.
   - Los pasos incluyen: correcci칩n de valores nulos, escalado de variables, normalizaci칩n, codificaci칩n de caracter칤sticas categ칩ricas, etc.

3. **Divisi칩n de datos**:
   - **Conjunto de entrenamiento**: Se usa para ajustar el modelo.
   - **Conjunto de validaci칩n**: Se usa para ajustar y validar el modelo durante el entrenamiento.
   - **Conjunto de prueba**: Se usa para evaluar el modelo una vez entrenado, para conocer su desempe침o en datos que no ha visto.

4. **Entrenamiento**:
   - Ajustar los par치metros del modelo utilizando el conjunto de entrenamiento.
   - Proceso iterativo en el cual el modelo busca encontrar las mejores funciones o pesos que mejoran su capacidad para hacer predicciones.

5. **Evaluaci칩n**:
   - Medir el rendimiento del modelo utilizando m칠tricas adecuadas en el conjunto de prueba.
   - Las m칠tricas comunes incluyen:
     - **Precisi칩n**: La fracci칩n de aciertos en relaci칩n con todos los casos evaluados.
     - **Recall**: La capacidad del modelo de encontrar todos los casos positivos.
     - **F1-score**: Combinaci칩n entre precisi칩n y recall.
     - **Root Mean Square Error (RMSE)**: Para modelos de regresi칩n.
     - **Accuracy**: Porcentaje de aciertos en las predicciones.

#### Diagrama del proceso de Machine Learning:
- <img src="https://rchavarria.github.io/notes/assets/images/2018/machine-learning-process.png" alt="Descripci칩n de la imagen" width="700">

#### Ejemplo
  -[**`Ejemplo 4.1`**](ejemplo4_1/Ejemplo4_1.ipynb)

#### Ejercicio para alumnos 
- Clasificar diferentes casos de uso de Machine Learning como supervisados o no supervisados.

---

## Tema: Divisi칩n de Datos

### Tema 4.2: Entrenamiento, Validaci칩n y Prueba


**쯇or qu칠 dividir los datos?**
- La divisi칩n de los datos es crucial para **evitar el sobreajuste** al modelo y para **evaluar su rendimiento** en situaciones reales. El entrenamiento solo con un conjunto puede llevar a una evaluaci칩n optimista (desempe침o demasiado bueno en datos vistos).
- Al dividir los datos en conjuntos separados para **entrenamiento**, **validaci칩n** y **prueba**, se asegura que el modelo generalice bien a nuevos datos y que el rendimiento del modelo sea medible de manera precisa.

---

#### Divisiones comunes de los datos:

1. **Conjunto de Entrenamiento (60-80%)**:
   - **Prop칩sito**: Se utiliza para ajustar el modelo, aprendiendo los patrones y relaciones existentes en los datos.
   - Este conjunto es donde se entrena el modelo aplicando los algoritmos hasta que se ajuste correctamente al problema.
   - **Ventajas**: 
     - Ampl칤a la capacidad del modelo para generalizar a datos nuevos.
     - Permite ajustar los par치metros internos del modelo a partir del conjunto de entrada.
   - **Ejemplo**: Cuando se trabaja con datos de ventas, los datos de entrenamiento ser치n utilizados para ajustar las caracter칤sticas del modelo que predicen los resultados de ventas futuras.

2. **Conjunto de Validaci칩n (10-20%)**:
   - **Prop칩sito**: Este conjunto se usa para ajustar los **hiperpar치metros** del modelo, como la tasa de aprendizaje, el n칰mero de vecinos en **KNN**, o el **threshold** en un clasificador.
   - El modelo puede ajustar el rendimiento seg칰n la validaci칩n antes de su implementaci칩n final.
   - **Ventajas**: Permite comparar el desempe침o de varias configuraciones del modelo.
   - **Ejemplo**: Ajustar el n칰mero de 칠pocas en un modelo de red neuronal para evitar el **overfitting** o el **underfitting**.

3. **Conjunto de Prueba (10-20%)**:
   - **Prop칩sito**: Se usa para evaluar el rendimiento final del modelo, proporcionando una m칠trica objetiva de su capacidad para hacer predicciones en datos nuevos que no ha visto.
   - Es vital que este conjunto no se haya utilizado previamente en ninguna etapa de entrenamiento o validaci칩n.
   - **Ventajas**:
      - **Evaluaci칩n Objetiva**: Permite medir el rendimiento del modelo en datos que nunca antes ha visto, lo que proporciona una estimaci칩n m치s realista de su capacidad para generalizar a situaciones nuevas.
      - **Verificaci칩n Final**: Sirve como un paso final para validar si el modelo es capaz de realizar predicciones precisas en escenarios reales, antes de su implementaci칩n comercial o en producci칩n.
      - **Minimiza el Overfitting**: Al utilizar datos completamente nuevos, evita el sobreajuste al garantizar que el modelo no ha aprendido patrones espec칤ficos de los datos utilizados en el entrenamiento o validaci칩n.
   - **Ejemplo**: Evaluar el desempe침o de un modelo clasificador en una muestra de datos completamente nueva y separada, como la predicci칩n de enfermedades en una poblaci칩n distinta.

- <img src="https://keepcoding.io/wp-content/uploads/2022/08/image-202-1024x565.png" alt="Descripci칩n de la imagen" width="700">
---

#### T칠cnicas de validaci칩n cruzada:

1. **K-Fold Cross Validation**:
   - **Descripci칩n**: Divide el conjunto de datos en `k` subconjuntos iguales o aproximadamente iguales. 
   - Se entrena y eval칰a el modelo `k` veces, utilizando diferentes subconjuntos para el entrenamiento cada vez, dejando un subconjunto como prueba.
   - **Ventajas**:
     - Proporciona una estimaci칩n m치s robusta del rendimiento del modelo al entrenar y evaluar m칰ltiples veces.
     - Minimiza el sesgo que podr칤a surgir por una partici칩n accidentalmente desbalanceada.
   - **Ejemplo**: Si `k=5`, el conjunto de datos se divide en cinco partes iguales y el modelo es entrenado y validado cinco veces usando diferentes combinaciones.

2. **Leave-One-Out Cross Validation (LOOCV)**:
   - **Descripci칩n**: Usa un dato como conjunto de prueba y el resto como conjunto de entrenamiento. 
   - Este proceso se repite hasta que todos los datos han servido como conjunto de prueba una vez.
   - **Ventajas**:
     - Minimiza el sesgo, ya que utiliza todos los datos en la fase de entrenamiento.
   - **Ejemplo**: Ideal para peque침as bases de datos donde el n칰mero total de datos es peque침o.

3. **Stratified K-Fold Cross Validation**:
   - **Descripci칩n**: Similar a K-Fold, pero asegura que las clases est칠n equilibradas en cada divisi칩n. 
   - Muy 칰til cuando los datos est치n desbalanceados, como en problemas de clasificaci칩n binaria.
   - **Ventajas**:
     - Mantiene la proporci칩n de clases en cada subsampleo, lo que evita que las clases minoritarias influyan de manera excesiva en el entrenamiento.
   - **Ejemplo**: En una base de datos con 90% de datos de clase A y 10% de clase B, el **Stratified K-Fold** asegura que cada divisi칩n mantenga esa proporci칩n.

---

#### Otras t칠cnicas de validaci칩n:

1. **Bootstrap**:
   - **Descripci칩n**: Genera m칰ltiples conjuntos de entrenamiento a partir del conjunto original mediante muestreo con reemplazo.
   - Esto permite evaluar la estabilidad y la varianza del modelo al generar m칰ltiples subconjuntos.
   - **Ventajas**:
     - Proporciona una estimaci칩n m치s robusta del rendimiento del modelo.
     - Permite identificar la incertidumbre asociada con el desempe침o del modelo.
   - **Ejemplo**: Ideal para realizar inferencias sobre el desempe침o del modelo cuando se tienen muestras peque침as.

2. **Under-Sampling**:
   - **Descripci칩n**: Consiste en eliminar muestras de la mayor칤a de clases para igualar el n칰mero de instancias de las clases minoritarias.
   - **Ventajas**:
     - Ayuda a mitigar el sesgo cuando los datos est치n desbalanceados.
   - **Ejemplo**: En conjuntos de datos con m치s casos negativos que positivos (clasificaci칩n binaria), el **under-sampling** permite reducir el n칰mero de negativos.

3. **Over-Sampling**:
   - **Descripci칩n**: Aumenta las muestras de las clases minoritarias mediante t칠cnicas como **SMOTE** (Synthetic Minority Over-sampling Technique).
   - **Ventajas**:
     - Reduce el problema del sesgo al aumentar las instancias de clases minoritarias.
   - **Ejemplo**: En conjuntos de datos con pocos casos positivos en una clasificaci칩n binaria, el **over-sampling** ayuda a equilibrar las clases.

---

#### Otras t칠cnicas importantes para la validaci칩n de modelos:

- **Grid Search**:
  - **Descripci칩n**: T칠cnica que busca encontrar los mejores hiperpar치metros en un espacio definido. 
  - Se realiza explorando exhaustivamente todas las combinaciones posibles.
  - **Ventajas**:
    - Garantiza encontrar un conjunto 칩ptimo de hiperpar치metros.
  - **Desventajas**:
    - Computacionalmente costoso para grandes conjuntos de par치metros.

- **Random Search**:
  - **Descripci칩n**: Similar al **Grid Search**, pero explora de manera aleatoria las configuraciones posibles de hiperpar치metros.
  - **Ventajas**:
    - M치s eficiente computacionalmente que el **Grid Search** y proporciona buenos resultados en muchos casos.
  - **Ejemplo**: Cuando se buscan las mejores combinaciones de **learning rate**, **n칰mero de capas** o **n칰mero de vecinos**.

- **Early Stopping**:
  - **Descripci칩n**: Esta t칠cnica se usa para detener el entrenamiento cuando el desempe침o en la validaci칩n deja de mejorar. 
  - **Ventajas**:
    - Evita el sobreajuste al detener el proceso antes de que el modelo aprenda patrones innecesarios que no contribuyen a una buena generalizaci칩n.
  - **Ejemplo**: Se detiene el entrenamiento cuando la p칠rdida en el conjunto de validaci칩n no mejora durante varias 칠pocas consecutivas.

#### Ejemplo 
   -[**`Ejemplo 4.2`**](ejemplo4.2/Ejemplo4_2.ipynb)
   
---

## Tema: Modelos Supervisados

### Tema 4.3: Regresi칩n Lineal

- La **regresi칩n lineal** es un modelo supervisado que establece una relaci칩n lineal entre las variables independientes (features) y una variable dependiente (target).
- Es uno de los modelos m치s b치sicos en Machine Learning, utilizado com칰nmente para **predecir** resultados continuos, como precios, ingresos o temperaturas.
- **Ejemplo pr치ctico**: Predecir el precio de una casa basado en caracter칤sticas como su tama침o, ubicaci칩n, antig칲edad, n칰mero de habitaciones, etc.

**Ecuaci칩n del modelo**:
\[y = mx + b\]
- **m** es la pendiente, que representa la inclinaci칩n de la l칤nea, es decir, cu치nto cambia la variable dependiente (`y`) cuando la variable independiente (`x`) aumenta en una unidad.
- **b** es el intercepto, es decir, el punto en el eje `y` donde la l칤nea cruza al no tener ninguna influencia de la variable independiente.

**Entrenamiento del modelo**:
- La regresi칩n lineal se entrena **minimizando el error cuadr치tico medio (MSE)**, que mide la diferencia entre los valores reales y los valores predichos.
- El objetivo es encontrar los valores 칩ptimos de `m` (pendiente) y `b` (intercepto) que minimizan el MSE. Esto asegura que la l칤nea sea la m치s ajustada a los datos.

**Formas adicionales de entrenamiento**:
- **Gradient Descent**: T칠cnica com칰nmente utilizada para encontrar el conjunto 칩ptimo de `m` y `b` a trav칠s de iteraciones que ajustan los par치metros siguiendo el descenso del gradiente.
- **Normal Equation**: Proporciona una f칩rmula algebraica directa para encontrar `m` y `b`, ideal cuando el conjunto de datos es peque침o y no hay colinealidad entre las variables.

**Ventajas de la Regresi칩n Lineal**:
- **F치cil de interpretar**: Los coeficientes (`m` y `b`) tienen un significado claro en t칠rminos del impacto de las variables independientes en la variable dependiente.
- **R치pido de implementar**: Se puede entrenar r치pidamente y obtener predicciones basadas en datos relativamente simples.
- **Escalabilidad**: Es f치cil extenderla a m칰ltiples variables y se puede aplicar tanto a problemas con una como con m칰ltiples variables.

**Desventajas de la Regresi칩n Lineal**:
- **Asumida Linealidad**: Asume que la relaci칩n entre las variables es estrictamente lineal, lo que puede llevar a malos resultados si los datos tienen relaciones no lineales.
- **Sensibilidad a Outliers**: La regresi칩n lineal es afectada negativamente por **outliers**, ya que estos distorsionan los c치lculos del MSE.
- **Restricci칩n de normalidad**: Asume que los errores siguen una distribuci칩n normal, lo cual puede ser inapropiado para ciertos conjuntos de datos.

- <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png" alt="Descripci칩n de la imagen" width="500">

#### Ejemplo 
  -[**`Ejemplo 4.3`**](ejemplo4.3/Ejemplo4_3.ipynb)

#### Ejercicio 4.1 (Alumnos)
 -[**`Ejercicio 4.1`**](ejercicio4.1/Ejercicio4_1.ipynb)

---

### Tema 3.4: Clasificaci칩n

- La **clasificaci칩n** es un tipo de problema supervisado donde el objetivo es predecir **etiquetas categ칩ricas** o clases de salida. Las clases pueden ser binarias (spam/no spam) o multiclasificaci칩n (categor칤as como documentos de texto, tipos de flores, clases de im치genes, etc.).
- Ejemplos comunes de clasificaci칩n incluyen **detectar si un correo es spam o no spam**, **clasificar pacientes con base en diagn칩stico** o **predecir si un cliente realiza una compra o no**.

---

### Algoritmo k-Nearest Neighbors (k-NN):

- **k-Nearest Neighbors (k-NN)** es uno de los algoritmos m치s sencillos y efectivos para problemas de clasificaci칩n. 
- Utiliza la **distancia** entre puntos en el espacio de caracter칤sticas para asignar una clase a un nuevo dato basado en los `k` vecinos m치s cercanos.
  
1. **Seleccionar** un nuevo dato o punto de inter칠s.
2. **Calcular** la distancia entre este nuevo punto y todos los puntos en el conjunto de entrenamiento. Las distancias se miden com칰nmente utilizando:
   - **Distancia Euclidiana**:
   - <img src="https://upload.wikimedia.org/wikipedia/commons/6/67/Distance_Formula.svg" alt="Descripci칩n de la imagen" width="500">
   - **Distancia Manhattan**:
   - <img src="https://medidassimdist.wordpress.com/wp-content/uploads/2019/04/image-11.png" alt="Descripci칩n de la imagen" width="500">
3. **Seleccionar** los `k` vecinos m치s cercanos en funci칩n de la distancia calculada.
4. **Asignar** la clase basada en el modo (mayor칤a) de las etiquetas de estos `k` vecinos.
   
**Ventajas del k-NN**:
- **Sencillo y f치cil de entender**: No requiere entrenamiento complejo; simplemente almacena los datos y los compara con nuevos puntos.
- **Escalabilidad**: Es flexible y puede ser utilizado tanto con datos peque침os como grandes.
- **No necesita hiperpar치metros complejos**: Solo se elige el valor de `k`.

**Desventajas del k-NN**:
- **Sensibilidad a los outliers**: Los puntos at칤picos (outliers) pueden afectar la clasificaci칩n debido a su influencia en las distancias.
- **Requiere mucho espacio de almacenamiento**: A medida que los datos aumentan, el algoritmo necesita m치s memoria para almacenar los puntos de entrenamiento.
- **Complejidad computacional**: En datos grandes, el c치lculo de las distancias puede ser costoso en t칠rminos de tiempo.

- <img src="https://db0dce98.rocketcdn.me/es/files/2020/11/Illu-2-KNN-1024x492.jpg" alt="Descripci칩n de la imagen" width="500">

#### Ejemplo 
  -[**`Ejemplo 4.4`**](ejemplo4.4/Ejemplo4_4.ipynb)

#### Ejercicio 4.2 (Alumnos)
  --[**`Ejercicio 4.2`**](ejemplo4.2/Ejemplo4_2.ipynb)

---

## Tema: Modelos No Supervisados

### Tema 3.5: Clustering con K-Means

---

### **Definici칩n de Clustering**:
- **Clustering** es una t칠cnica de aprendizaje no supervisado que **agrupa datos** en conjuntos (cl칰steres) bas치ndose en sus **similitudes** o caracter칤sticas compartidas. 
- Los puntos en el mismo cl칰ster son **m치s similares** entre s칤 que con los puntos de otros cl칰steres.
- **Ejemplos de aplicaci칩n**:
  - Agrupamiento de clientes seg칰n su comportamiento de compra (marketing).
  - Identificaci칩n de patrones en datos gen칩micos (bioinform치tica).
  - Segmentaci칩n de im치genes en visi칩n por computadora.

---

### **Funcionamiento de K-Means**:

**Definici칩n**:
- El algoritmo **K-Means** es uno de los m칠todos de clustering m치s populares, que organiza los datos en **k** cl칰steres bas치ndose en la proximidad a centroides.
- <img src="https://images.javatpoint.com/tutorial/machine-learning/images/k-means-clustering-algorithm-in-machine-learning.png" alt="Descripci칩n de la imagen" width="500">

---

### **Ventajas del K-Means**:
- **Simplicidad**: F치cil de entender e implementar.
- **Escalabilidad**: Puede manejar grandes vol칰menes de datos de manera eficiente.
- **Flexibilidad**: Funciona bien con datos esf칠ricos y distribuciones homog칠neas.

---

### **Desventajas del K-Means**:
- **Dependencia de `k`**:
  - Requiere predefinir el n칰mero de cl칰steres (`k`), lo cual puede ser dif칤cil sin conocimiento previo.
  - T칠cnicas como el **M칠todo del Codo** ayudan a seleccionar un valor 칩ptimo de `k`.

- **Sensibilidad a Outliers**:
  - Los datos at칤picos pueden distorsionar los centroides y la asignaci칩n de cl칰steres.

- **Forma de los Cl칰steres**:
  - Funciona mejor con cl칰steres esf칠ricos y uniformemente distribuidos; no maneja bien formas irregulares.

---

### **Aplicaciones del K-Means**:
- **Segmentaci칩n de Clientes**:
  - Agrupa consumidores seg칰n sus patrones de compra para personalizar estrategias de marketing.
- **Compresi칩n de Im치genes**:
  - Reduce el n칰mero de colores en una imagen, agrupando p칤xeles con colores similares.
- **An치lisis de Datos Gen칠ticos**:
  - Clasifica genes o muestras seg칰n patrones de expresi칩n similares.

---

### **Visualizaci칩n del Proceso**:
- <img src="https://blog.thedigitalgroup.com/assets/uploads/k-means3.jpg" alt="Descripci칩n de la imagen" width="500">

#### Ejemplo 
  --[**`Ejemplo 4.5`**](ejemplo4.5/Ejemplo4_5.ipynb)

---

## Tema: Evaluaci칩n de Modelos

### Tema 4.6: M칠tricas de Evaluaci칩n

---

### **Evaluaci칩n para Clasificaci칩n**

Las m칠tricas de evaluaci칩n para problemas de clasificaci칩n miden qu칠 tan bien un modelo predice las clases correctas. Entre las m치s comunes se encuentran:

---

#### **1. Accuracy (Precisi칩n Global):**
- Mide la proporci칩n de predicciones correctas en relaci칩n con el total de predicciones realizadas.
- <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BAccuracy%7D%20%3D%20%5Cfrac%7B%5Ctext%7BPredicciones%20Correctas%7D%7D%7B%5Ctext%7BTotal%20de%20Predicciones%7D%7D" alt="Descripci칩n de la imagen" width="300">
- **Ventajas**:
  - F치cil de interpretar.
  - 칔til cuando las clases est치n equilibradas.
- **Desventajas**:
  - No es fiable si las clases est치n desbalanceadas (por ejemplo, 95% de una clase y 5% de otra).

---

#### **2. Precisi칩n (Precision):**
- Indica qu칠 proporci칩n de las predicciones positivas son realmente positivas.
- <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BPrecision%7D%20%3D%20%5Cfrac%7B%5Ctext%7BTrue%20Positives%20%28TP%29%7D%7D%7B%5Ctext%7BTrue%20Positives%20%28TP%29%20%2B%20False%20Positives%20%28FP%29%7D%7D" alt="Descripci칩n de la imagen" width="300">
- **Aplicaci칩n**: 칔til en casos donde es crucial minimizar falsos positivos (por ejemplo, detecci칩n de spam)
- **Ventajas**:
  - Es ideal en problemas donde las consecuencias de los falsos positivos son graves, como en la clasificaci칩n de correos no deseados o detecci칩n de fraudes.
  - Ofrece una m칠trica clara cuando el inter칠s principal est치 en la calidad de las predicciones positivas.
- **Desventajas**:
  - No considera los falsos negativos, por lo que puede ser enga침osa en problemas donde estos tienen un impacto significativo (por ejemplo, diagn칩stico m칠dico).
  - En datasets desbalanceados, puede ofrecer resultados sesgados si una clase domina las predicciones positivas.

---

#### **3. Recall (Sensibilidad o Tasa de Verdaderos Positivos):**
- Mide la proporci칩n de positivos reales que fueron correctamente identificados.
- <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BRecall%7D%20%3D%20%5Cfrac%7B%5Ctext%7BTrue%20Positives%20%28TP%29%7D%7D%7B%5Ctext%7BTrue%20Positives%20%28TP%29%20%2B%20False%20Negatives%20%28FN%29%7D%7D" alt="Descripci칩n de la imagen" width="300">
- **Aplicaci칩n**: Importante en problemas donde los falsos negativos tienen un alto costo (por ejemplo, diagn칩stico m칠dico).
- **Ventajas**:
  - Es 칰til cuando los falsos negativos deben minimizarse al m치ximo, como en problemas cr칤ticos de salud o seguridad.
  - Proporciona una visi칩n completa de cu치ntos positivos reales son correctamente identificados.
- **Desventajas**:
  - No considera los falsos positivos, lo que puede llevar a sobreestimar el desempe침o en problemas donde estos tienen impacto.
  - Si se optimiza 칰nicamente el recall, pueden aumentar los falsos positivos.


---

#### **4. F1-Score:**
- Es la media arm칩nica entre precisi칩n y recall, proporcionando un equilibrio entre ambas m칠tricas.
- <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BF1-Score%7D%20%3D%202%20%5Ccdot%20%5Cfrac%7B%5Ctext%7BPrecision%7D%20%5Ccdot%20%5Ctext%7BRecall%7D%7D%7B%5Ctext%7BPrecision%7D%20%2B%20%5Ctext%7BRecall%7D%7D" alt="Descripci칩n de la imagen" width="300">
- **Aplicaci칩n**: 칔til cuando hay un desbalance entre las clases y se requiere un balance entre precisi칩n y recall.
- **Ventajas**:
  - Equilibra precisi칩n y recall, siendo ideal para problemas con clases desbalanceadas donde ambos errores (falsos positivos y negativos) son relevantes.
  - Proporciona una 칰nica m칠trica que resume el desempe침o general del modelo.
- **Desventajas**:
  - No ofrece un an치lisis detallado de precisi칩n y recall por separado, lo que puede ocultar problemas espec칤ficos en el modelo.
  - No es f치cil de interpretar directamente si el contexto del problema no est치 claro.


---

#### **5. Matriz de Confusi칩n:**
- Es una tabla que describe el desempe침o del modelo, mostrando las predicciones correctas e incorrectas para cada clase.
  
  |                | Predicci칩n Positiva | Predicci칩n Negativa |
  |----------------|---------------------|---------------------|
  | **Clase Positiva** | True Positive (TP)    | False Negative (FN)   |
  | **Clase Negativa** | False Positive (FP)   | True Negative (TN)    |

- **Ventajas**:
  - Permite calcular m칰ltiples m칠tricas (precisi칩n, recall, etc.).
  - Proporciona una visi칩n detallada del desempe침o del modelo.

---

### **Evaluaci칩n para Regresi칩n**

En problemas de regresi칩n, las m칠tricas eval칰an qu칠 tan cerca est치n las predicciones del modelo de los valores reales.

---

#### **1. Error Absoluto Medio (MAE):**
- Promedio de los valores absolutos de los errores entre predicciones y valores reales.
- <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BMAE%7D%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi%3D1%7D%5En%20%7Cy_i%20-%20%5Chat%7By%7D_i%7C" alt="Descripci칩n de la imagen" width="300">
- **Ventajas**:
  - F치cil de interpretar.
  - No amplifica grandes errores como el MSE.
- **Desventajas**:
  - No penaliza errores grandes.

---

#### **2. Error Cuadr치tico Medio (MSE):**
- Promedio de los cuadrados de los errores entre predicciones y valores reales.
- <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BMSE%7D%20%3D%20%5Cfrac%7B1%7D%7Bn%7D%20%5Csum_%7Bi%3D1%7D%5En%20%28y_i%20-%20%5Chat%7By%7D_i%29%5E2" alt="Descripci칩n de la imagen" width="300">
- **Ventajas**:
- **Ventajas**:
  - Penaliza los errores grandes, siendo 칰til para modelos donde estos son cr칤ticos.
- **Desventajas**:
  - Puede ser influido en exceso por outliers.

---

#### **3. Coeficiente de Determinaci칩n ($R^2$):**
- Mide qu칠 proporci칩n de la variaci칩n en los datos es explicada por el modelo.
- <img src="https://latex.codecogs.com/png.latex?R%5E2%20%3D%201%20-%20%5Cfrac%7B%5Ctext%7BSSE%7D%7D%7B%5Ctext%7BSST%7D%7D" alt="Descripci칩n de la imagen" width="300">
- **Ventajas**:
- **Interpretaci칩n**:
  - $R^2 = 1$: El modelo explica perfectamente los datos.
  - $R^2 = 0$: El modelo no explica ninguna variaci칩n.
  - $R^2 < 0$: El modelo es peor que simplemente usar la media como predicci칩n.

---

#### Ejemplo 
  --[**`Ejemplo 4.6`**](ejemplo4.6/ejemplo4_6.ipynb)
  
#### Ejercicio 4.3 (Alumnos)
  -[**`Ejercicio 4.3`**](ejercicio4.3/ejercicio4_3.ipynb)

#### Ejercicio Unificado
  -[**`Ejercicio Unificado`**](Ejercicio_Unificado_Modulo_4_Alumno.ipynb)

#### Ejercicio Final
  -[**`Ejercicio Final`**](Ejercicio_Final_Modelo_Machine_Learning_Student.ipynb)
